# InstruÃ§Ãµes para ExecuÃ§Ã£o dos Testes - Meta Campaign Manager

## Setup Inicial

### Backend (Python/FastAPI)

```bash
cd backend

# 1. Ativar ambiente virtual
source venv/bin/activate

# 2. Instalar dependÃªncias de teste
pip install -r requirements-test.txt

# 3. Verificar instalaÃ§Ã£o
pytest --version
```

### Frontend (Next.js/TypeScript)

```bash
cd frontend

# 1. Instalar dependÃªncias de teste
npm install

# As dependÃªncias de teste jÃ¡ estÃ£o em package.json:
# - vitest
# - @testing-library/react
# - @testing-library/jest-dom
# - jsdom
# - @vitest/coverage-v8
```

---

## Executar Testes

### Backend

#### Executar todos os testes
```bash
cd backend
pytest
```

#### Executar testes com cobertura
```bash
pytest --cov=app --cov-report=html --cov-report=term
```

#### Executar testes especÃ­ficos
```bash
# Teste de um arquivo especÃ­fico
pytest backend/tests/test_meta_api.py -v

# Teste de uma funÃ§Ã£o especÃ­fica
pytest backend/tests/test_meta_api.py::test_list_campaigns_success -v

# Testes marcados (unitÃ¡rios apenas)
pytest -m unit

# Excluir testes de integraÃ§Ã£o
pytest -m "not integration"
```

#### Watch mode (rerun on changes)
```bash
ptw  # ou pytest-watch
```

#### Executar em paralelo (mais rÃ¡pido)
```bash
pytest -n auto  # usa todos os CPUs disponÃ­veis
```

#### Gerar relatÃ³rio de cobertura HTML
```bash
pytest --cov=app --cov-report=html
open coverage_html/index.html  # macOS
```

---

### Frontend

#### Executar todos os testes
```bash
cd frontend
npm run test
```

#### Executar com cobertura
```bash
npm run test:coverage
```

#### Watch mode
```bash
npm run test:watch
```

#### UI mode (interface grÃ¡fica)
```bash
npm run test:ui
```

#### Executar testes especÃ­ficos
```bash
# Teste de um arquivo especÃ­fico
npm run test src/lib/__tests__/rate-limit.test.ts

# Executar apenas testes modificados
npm run test -- --changed
```

#### Gerar relatÃ³rio de cobertura
```bash
npm run test:coverage
open coverage/index.html  # macOS
```

---

## Estrutura de DiretÃ³rios de Testes

```
meta/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_meta_api.py          # âœ… Criado (TDD cycles 1-5)
â”‚   â”‚   â”œâ”€â”€ test_api_campaigns.py     # TODO: TDD cycles 6-8
â”‚   â”‚   â””â”€â”€ test_integration_meta_api.py  # TODO: Integration tests
â”‚   â”œâ”€â”€ conftest.py                    # âœ… Criado (fixtures compartilhados)
â”‚   â”œâ”€â”€ pytest.ini                     # âœ… Criado (configuraÃ§Ã£o pytest)
â”‚   â””â”€â”€ requirements-test.txt          # âœ… Criado (dependÃªncias)
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ src/
    â”‚   â””â”€â”€ lib/
    â”‚       â””â”€â”€ __tests__/
    â”‚           â”œâ”€â”€ rate-limit.test.ts  # âœ… Criado (TDD cycle 9)
    â”‚           â””â”€â”€ logger.test.ts      # âœ… Criado (TDD cycle 10)
    â”œâ”€â”€ vitest.config.ts               # âœ… Criado (configuraÃ§Ã£o Vitest)
    â”œâ”€â”€ vitest.setup.ts                # âœ… Criado (setup global)
    â””â”€â”€ package.json                   # âœ… Atualizado (scripts + deps)
```

---

## Verificar Cobertura

### Backend

```bash
cd backend
pytest --cov=app --cov-report=term-missing

# Exemplo de saÃ­da esperada:
# Name                                Stmts   Miss  Cover   Missing
# -----------------------------------------------------------------
# app/tools/meta_api.py                 150      15    90%   45-50, 120
# -----------------------------------------------------------------
# TOTAL                                 500     100    80%
```

### Frontend

```bash
cd frontend
npm run test:coverage

# Exemplo de saÃ­da esperada:
# File                          | % Stmts | % Branch | % Funcs | % Lines
# -----------------------------------------------------------------
# src/lib/rate-limit.ts         |   100   |   100    |   100   |   100
# src/lib/logger.ts             |   95    |   90     |   100   |   95
# -----------------------------------------------------------------
# All files                     |   85    |   80     |   85    |   85
```

---

## MÃ©tricas de Cobertura Alvo

### Alvo MÃ­nimo (80%)

| Componente | Cobertura Alvo | Status |
|------------|---------------|--------|
| `backend/app/tools/meta_api.py` | 90%+ | ğŸ”„ Em progresso |
| `backend/app/api/campaigns.py` | 85%+ | â³ Pendente |
| `frontend/src/lib/rate-limit.ts` | 100% | âœ… Completo |
| `frontend/src/lib/logger.ts` | 100% | âœ… Completo |
| `frontend/src/app/api/sync/route.ts` | 85%+ | â³ Pendente |
| `frontend/src/app/api/dashboard/route.ts` | 80%+ | â³ Pendente |

---

## Troubleshooting

### Backend

#### Erro: `ModuleNotFoundError: No module named 'app'`
```bash
# SoluÃ§Ã£o: Adicionar diretÃ³rio raiz ao PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:/Users/guilhermecosta/Projetos/meta/backend"
```

#### Erro: `asyncio.exceptions.RuntimeWarning`
```bash
# SoluÃ§Ã£o: JÃ¡ configurado em pytest.ini com asyncio_mode = auto
```

#### Erro: `httpx.TimeoutException`
```bash
# SoluÃ§Ã£o: Aumentar timeout nos testes
# Ou verificar se mock estÃ¡ configurado corretamente
```

---

### Frontend

#### Erro: `Cannot find module '@/lib/...'`
```bash
# SoluÃ§Ã£o: JÃ¡ configurado em vitest.config.ts com alias
```

#### Erro: `ReferenceError: global is not defined`
```bash
# SoluÃ§Ã£o: JÃ¡ configurado em vitest.config.ts com environment: 'jsdom'
```

#### Erro: `TypeError: vi is not defined`
```bash
# SoluÃ§Ã£o: Adicionar `globals: true` em vitest.config.ts (jÃ¡ configurado)
```

---

## PrÃ³ximos Passos

### Fase 1: Completar Backend Tests (Semana 1)
```bash
# 1. Executar testes existentes
cd backend
pytest backend/tests/test_meta_api.py -v

# 2. Verificar cobertura
pytest --cov=app.tools.meta_api --cov-report=term-missing

# 3. Implementar testes faltantes (TDD cycles 6-8)
# - test_api_campaigns.py
# - Aumentar cobertura para 90%+
```

### Fase 2: Completar Frontend Tests (Semana 2)
```bash
# 1. Executar testes existentes
cd frontend
npm run test

# 2. Verificar cobertura
npm run test:coverage

# 3. Implementar testes faltantes (TDD cycles 11-12)
# - app/api/sync/__tests__/route.test.ts
# - app/api/dashboard/__tests__/route.test.ts
```

### Fase 3: CI/CD (Semana 3)
```bash
# Configurar GitHub Actions para executar testes automaticamente
# Ver: .github/workflows/tests.yml
```

---

## Comandos Ãšteis

### Backend

```bash
# Limpar cache
pytest --cache-clear

# Verbose output
pytest -vv

# Mostrar print statements
pytest -s

# Parar no primeiro erro
pytest -x

# Executar Ãºltimo teste que falhou
pytest --lf

# Gerar relatÃ³rio JUnit (para CI/CD)
pytest --junitxml=test-results.xml
```

### Frontend

```bash
# Limpar cache
npm run test -- --clearCache

# Executar apenas testes modificados
npm run test -- --changed

# Atualizar snapshots
npm run test -- -u

# Executar com debug
npm run test -- --inspect-brk

# Gerar relatÃ³rio JSON
npm run test:coverage -- --reporter=json
```

---

## Recursos Adicionais

- **Pytest Docs**: https://docs.pytest.org/
- **Vitest Docs**: https://vitest.dev/
- **Testing Library**: https://testing-library.com/
- **TDD Guide**: Kent Beck - "Test Driven Development: By Example"
- **Plano de Testes Completo**: `/Users/guilhermecosta/Projetos/meta/PLANO_TESTES.md`

---

## Suporte

Se encontrar problemas:
1. Verificar logs de erro
2. Consultar PLANO_TESTES.md
3. Executar testes em modo verbose (`-vv`)
4. Verificar configuraÃ§Ã£o em `pytest.ini` ou `vitest.config.ts`
